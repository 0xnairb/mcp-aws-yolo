{
  "servers": [
    {
      "id": 1,
      "server_id": "awslabs.aws-api-mcp-server",
      "name": "AWS API MCP Server",
      "description": "The AWS API MCP Server is an AI assistant tool that bridges AI assistants and AWS services through programmatic AWS CLI commands. Features comprehensive AWS CLI support with command validation to prevent model hallucination, security-first design with multiple protection layers including read-only mode for safe resource exploration, and flexible credential management. Provides access to latest AWS API features for creating, updating, and managing AWS resources. Includes tools for executing AWS CLI commands and generating commands from natural language queries. Ideal for developers seeking secure, programmatic AWS resource management in testing, development, and evaluation environments.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.aws-api-mcp-server@latest"],
      "env": {
        "AWS_REGION": "{{env:aws_region}}",
        "AWS_API_MCP_PROFILE_NAME": "{{env:aws_profile}}",
        "READ_OPERATIONS_ONLY": "{{env:read_only_mode}}",
        "REQUIRE_MUTATION_CONSENT": "{{env:require_consent}}",
        "AWS_API_MCP_TELEMETRY": "{{env:enable_telemetry}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["aws_cli", "aws_api", "infrastructure_management", "call_aws", "suggest_aws_commands"],
      "domains": ["aws", "cloud", "infrastructure"],
      "keywords": ["aws", "mcp", "api", "cli", "infrastructure"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Configure AWS credentials:\\n   - aws configure (for default profile)\\n   - Or set AWS_ACCESS_KEY_ID/AWS_SECRET_ACCESS_KEY env vars\\n3. Set preferences:\\n   - vault set aws_region 'your-preferred-region' (default: us-east-1)\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set read_only_mode 'true' (recommended for safety)\\n   - vault set require_consent 'true' (recommended)\\n   - vault set enable_telemetry 'true' (optional)\\n4. Ensure proper IAM permissions for intended operations"
    },
    {
      "id": 2,
      "server_id": "aws-knowledge-mcp-server",
      "name": "AWS Knowledge MCP Server",
      "description": "A fully managed remote MCP server providing comprehensive, real-time access to AWS knowledge and documentation resources. Offers up-to-date AWS documentation, API references, architectural guidance, getting started guides, builder center content, blog posts, and Well-Architected guidance. Features natural language query support for AWS technologies, structured knowledge access for AI agents, and minimal local setup requirements. Currently in preview release with no AWS account required, accessible via HTTP transport and subject to rate limits. Includes tools for documentation search and retrieval, covering latest AWS documentation, API references, What's New posts, and best practices for AWS APIs and services.",
      "version": "1.0.0",
      "execution_type": "REMOTE",
      "security_level": "PUBLIC",
      "command": "uvx",
      "args": ["mcp-proxy", "--transport", "streamablehttp", "https://knowledge-mcp.global.api.aws"],
      "env": {},
      "categories": ["DOCUMENTATION"],
      "capabilities": ["aws_documentation", "best_practices", "api_reference", "getting_started", "search_documentation", "read_documentation", "recommend"],
      "domains": ["aws", "documentation", "knowledge"],
      "keywords": ["aws", "mcp", "documentation", "knowledge", "best-practices"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. No additional configuration required - this is a fully managed remote server\\n3. No AWS account needed\\n4. Subject to rate limits\\n5. Test connection: npx @modelcontextprotocol/inspector https://knowledge-mcp.global.api.aws"
    },
    {
      "id": 3,
      "server_id": "awslabs.aurora-dsql-mcp-server",
      "name": "Amazon Aurora DSQL MCP Server",
      "description": "An AWS Labs Model Context Protocol (MCP) server designed specifically for Aurora DSQL database interactions. This server bridges natural language queries and structured database operations by converting human-readable questions into PostgreSQL-compatible SQL queries and executing them against configured Aurora DSQL clusters. Features intelligent query translation from natural language to SQL, connection reuse for improved performance, and security-first design with read-only mode by default and optional write capabilities via --allow-writes flag. Supports IAM role-based database authentication for secure access control. Ideal for AI-assisted database querying, data exploration, and analytical workflows where users need to interact with Aurora DSQL databases using natural language. Requires AWS account with Aurora DSQL cluster and appropriate IAM permissions for database access. Must run locally on the same host as the LLM client with configured AWS credentials.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": [
        "awslabs.aurora-dsql-mcp-server@latest",
        "--cluster_endpoint",
        "{{env:aurora_dsql_cluster_endpoint}}",
        "--region",
        "{{env:aurora_dsql_region}}",
        "--database_user",
        "{{env:aurora_dsql_username}}",
        "--profile",
        "{{env:aws_profile}}",
        "{{env:allow_writes_flag}}"
      ],
      "env": {"FASTMCP_LOG_LEVEL": "ERROR"},
      "categories": ["DATA"],
      "capabilities": ["sql_query", "database_access", "aurora_dsql", "postgres_compatible"],
      "domains": ["aws", "database", "sql", "aurora"],
      "keywords": ["aws", "mcp", "aurora", "dsql", "sql", "database"],
      "setup_instructions": "1. Create an Aurora DSQL cluster in AWS Console\\n2. Note your cluster endpoint and region\\n3. Store credentials in your local vault:\\n   - vault set aurora_dsql_cluster_endpoint 'your-cluster-endpoint'\\n   - vault set aurora_dsql_region 'your-region'\\n   - vault set aurora_dsql_username 'your-username'\\n4. Configure AWS credentials via aws configure\\n5. For write access, set allow_writes_flag to '--allow-writes' (optional)"
    },
    {
      "id": 4,
      "server_id": "awslabs.mysql-mcp-server",
      "name": "MySQL MCP Server",
      "description": "An AWS Labs Model Context Protocol (MCP) server designed for seamless MySQL database interactions through natural language processing. This server converts human-readable questions into MySQL-compatible SQL queries and executes them against configured Aurora MySQL databases via RDS Data API. Features intelligent natural language to SQL query translation, secure credential management through AWS Secrets Manager integration, and flexible read-only or read-write database operations. Supports local execution alongside LLM clients with AWS profile-based authentication and regional configuration flexibility. Default mode operates in read-only for security, with configurable write permissions for DML/DDL queries when needed. Ideal for AI-assisted database querying, data exploration, reporting workflows, and analytical tasks where users need to interact with MySQL databases using conversational language. Requires Python 3.10, AWS account with Aurora MySQL cluster, RDS Data API enabled, and appropriate IAM permissions for RDS Data API and Secrets Manager access. Must run locally with configured AWS credentials for secure database connectivity.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": [
        "awslabs.mysql-mcp-server@latest",
        "--resource_arn",
        "{{env:mysql_resource_arn}}",
        "--secret_arn", 
        "{{env:mysql_secret_arn}}",
        "--database",
        "{{env:mysql_database}}",
        "--region",
        "{{env:mysql_region}}",
        "--readonly",
        "{{env:mysql_readonly}}"
      ],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:mysql_region}}",
        "FASTMCP_LOG_LEVEL": "ERROR"
      },
      "categories": ["DATA"],
      "capabilities": ["mysql_query", "database_access", "aurora_mysql", "rds_data_api", "secrets_manager"],
      "domains": ["aws", "database", "mysql", "aurora"],
      "keywords": ["aws", "mcp", "mysql", "aurora", "rds", "data-api", "secrets-manager"],
      "setup_instructions": "1. Create Aurora MySQL cluster in AWS Console\\n2. Enable RDS Data API on your cluster\\n3. Store database credentials in AWS Secrets Manager\\n4. Note your resource ARN and secret ARN\\n5. Configure vault with connection details:\\n   - vault set mysql_resource_arn 'your-cluster-arn'\\n   - vault set mysql_secret_arn 'your-secret-arn'\\n   - vault set mysql_database 'your-db-name'\\n   - vault set mysql_region 'your-region'\\n   - vault set mysql_readonly 'True' (recommended)\\n6. Configure AWS credentials: aws configure\\n7. Ensure IAM permissions for RDS Data API and Secrets Manager"
    },
    {
      "id": 5,
      "server_id": "awslabs.postgres-mcp-server",
      "name": "PostgreSQL MCP Server",
      "description": "An AWS Labs Model Context Protocol (MCP) server designed for seamless PostgreSQL database interactions through natural language processing. This server converts human-readable questions into PostgreSQL-compatible SQL queries and executes them against configured Aurora PostgreSQL clusters using either RDS Data API or direct database connections. Features intelligent natural language to SQL query translation, dual connection methods for flexibility (RDS Data API for serverless operations or direct psycopg connection for better performance), secure credential management through AWS Secrets Manager integration, and configurable read-only or read-write database operations. Supports local execution alongside LLM clients with AWS profile-based authentication and flexible deployment options including Docker runtime support. Default mode operates in read-only for security, with configurable write permissions when needed. Ideal for AI-assisted database querying, data exploration, reporting workflows, and analytical tasks where users need to interact with PostgreSQL databases using conversational language. Requires Python 3.10, Docker runtime, AWS account with Aurora PostgreSQL cluster, optionally RDS Data API enabled, and appropriate IAM permissions for RDS Data API and Secrets Manager access. Must run locally with configured AWS credentials for secure database connectivity. Offers superior performance through direct connection option while maintaining serverless capabilities via RDS Data API.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": [
        "awslabs.postgres-mcp-server@latest",
        "{{env:postgres_connection_method}}",
        "{{env:postgres_connection_value}}",
        "--secret_arn", 
        "{{env:postgres_secret_arn}}",
        "--database",
        "{{env:postgres_database}}",
        "--region",
        "{{env:postgres_region}}",
        "--readonly",
        "{{env:postgres_readonly}}"
      ],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:postgres_region}}",
        "FASTMCP_LOG_LEVEL": "ERROR"
      },
      "categories": ["DATA"],
      "capabilities": ["postgres_query", "database_access", "aurora_postgres", "rds_data_api", "secrets_manager", "direct_connection"],
      "domains": ["aws", "database", "postgresql", "aurora"],
      "keywords": ["aws", "mcp", "postgresql", "postgres", "aurora", "rds", "data-api", "secrets-manager"],
      "setup_instructions": "1. Create Aurora PostgreSQL cluster in AWS Console\\n2. Choose connection method:\\n   - RDS Data API: Enable Data API on your cluster\\n   - Direct Connection: Note your cluster hostname\\n3. Store database credentials in AWS Secrets Manager\\n4. Note your resource ARN/hostname and secret ARN\\n5. Configure vault with connection details:\\n   - vault set postgres_connection_method '--resource_arn' (or '--hostname')\\n   - vault set postgres_connection_value 'your-cluster-arn-or-hostname'\\n   - vault set postgres_secret_arn 'your-secret-arn'\\n   - vault set postgres_database 'your-db-name'\\n   - vault set postgres_region 'your-region'\\n   - vault set postgres_readonly 'True' (recommended)\\n6. Configure AWS credentials: aws configure\\n7. Ensure IAM permissions for RDS Data API and Secrets Manager"
    },
    {
      "id": 6,
      "server_id": "awslabs.aws-bedrock-data-automation-mcp-server",
      "name": "AWS Bedrock Data Automation MCP Server",
      "description": "A Model Context Protocol (MCP) server that enables conversational interactions with AWS Bedrock Data Automation projects. Allows analysis of data assets, workflows, and insights through natural language commands. Provides tools to explore project assets, retrieve project details, and analyze data processing workflows.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.aws-bedrock-data-automation-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "AWS_BUCKET_NAME": "{{env:bedrock_s3_bucket}}",
        "BASE_DIR": "{{env:bedrock_base_dir}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["AI", "DATA"],
      "capabilities": ["bedrock_data_automation", "project_management", "data_analysis", "workflow_insights", "asset_analysis"],
      "domains": ["aws", "bedrock", "data-automation", "analytics"],
      "keywords": ["aws", "mcp", "bedrock", "data-automation", "analytics", "workflow"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Set up AWS Bedrock Data Automation in your AWS account\\n3. Create an S3 bucket for data assets\\n4. Configure vault with required parameters:\\n   - vault set bedrock_s3_bucket 'your-s3-bucket-name'\\n   - vault set bedrock_base_dir '/your/base/directory/path'\\n5. Configure AWS credentials: aws configure\\n6. Optional user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n7. Ensure IAM permissions for Bedrock Data Automation and S3 access"
    },
    {
      "id": 7,
      "server_id": "awslabs.cloudwatch-appsignals-mcp-server",
      "name": "AWS CloudWatch Application Signals MCP Server",
      "description": "A Model Context Protocol (MCP) server for AWS CloudWatch Application Signals. Provides comprehensive observability for distributed applications through SLIs, SLOs, transaction spans, traces, and service metrics. Enables AI assistants to monitor application performance and troubleshoot issues across microservices architectures.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.cloudwatch-appsignals-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["application_monitoring", "observability", "metrics_analysis", "trace_investigation", "sli_slo_tracking", "service_monitoring"],
      "domains": ["aws", "cloudwatch", "observability", "monitoring"],
      "keywords": ["aws", "mcp", "cloudwatch", "application-signals", "observability", "monitoring", "sli", "slo", "traces"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Enable AWS CloudWatch Application Signals in your AWS account\\n3. Ensure your applications are instrumented with OpenTelemetry\\n4. Configure AWS credentials: aws configure\\n5. Optional user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n6. Ensure IAM permissions for CloudWatch Application Signals, X-Ray, and CloudWatch Logs\\n7. Verify Application Signals is collecting data from your services"
    },
    {
      "id": 8,
      "server_id": "awslabs.cloudwatch-mcp-server",
      "name": "AWS CloudWatch MCP Server",
      "description": "A Model Context Protocol (MCP) server for AWS CloudWatch. Provides comprehensive access to CloudWatch metrics, alarms, and log analytics. Enables AI assistants to monitor AWS resources, analyze performance data, investigate alerts, and perform log analysis with CloudWatch Logs Insights. Essential tool for AWS infrastructure monitoring and troubleshooting.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.cloudwatch-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["cloudwatch_metrics", "alarm_management", "log_analytics", "monitoring", "insights_queries", "anomaly_detection"],
      "domains": ["aws", "cloudwatch", "monitoring", "logging"],
      "keywords": ["aws", "mcp", "cloudwatch", "metrics", "alarms", "logs", "monitoring", "insights"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Optional user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n5. Ensure IAM permissions for CloudWatch:\\n   - cloudwatch:GetMetricData\\n   - cloudwatch:ListMetrics\\n   - cloudwatch:DescribeAlarms\\n   - cloudwatch:GetMetricStatistics\\n   - logs:DescribeLogGroups\\n   - logs:StartQuery\\n   - logs:GetQueryResults\\n   - logs:FilterLogEvents\\n6. Test connection to verify CloudWatch access"
    },
    {
      "id": 9,
      "server_id": "aws.aws-dataprocessing-mcp-server",
      "name": "AWS Data Processing MCP Server",
      "description": "A Model Context Protocol (MCP) server for AWS data processing services. Provides comprehensive access to AWS Glue Data Catalog, EMR cluster management, Athena query operations, and ETL job orchestration. Enables AI assistants to manage data pipelines, execute analytics workloads, and perform interactive data processing with support for both read-only and write operations.",
      "version": "0.1.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": [
        "aws.aws-dataprocessing-mcp-server@latest",
        "{{env:allow_write_flag}}",
        "{{env:allow_sensitive_data_flag}}"
      ],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DATA", "DEVELOPMENT"],
      "capabilities": ["data_catalog_management", "emr_cluster_management", "athena_queries", "etl_orchestration", "data_processing", "glue_operations"],
      "domains": ["aws", "data-processing", "glue", "emr", "athena"],
      "keywords": ["aws", "mcp", "data-processing", "glue", "emr", "athena", "etl", "analytics"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\\\n2. Install Python 3.10+: uv python install 3.10\\\\n3. Configure AWS credentials: aws configure\\\\n4. Optional user preferences:\\\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\\\n   - vault set aws_region 'your-region' (default: us-east-1)\\\\n   - vault set allow_write_flag '--allow-write' (enables mutations, default: read-only)\\\\n   - vault set allow_sensitive_data_flag '--allow-sensitive-data-access' (enables sensitive data access)\\\\n   - vault set log_level 'WARNING' (default: WARNING)\\\\n5. Ensure IAM permissions for data processing services:\\\\n   - glue:* (for Data Catalog operations)\\\\n   - emr:* (for cluster management)\\\\n   - athena:* (for query operations)\\\\n   - s3:* (for data access)\\\\n   - iam:* (for resource management)\\\\n6. Test connection to verify data processing service access"
    },
    {
      "id": 10,
      "server_id": "awslabs.cdk-mcp-server",
      "name": "AWS CDK MCP Server",
      "description": "An AWS Labs Model Context Protocol (MCP) server that provides comprehensive guidance and automation tools for AWS Cloud Development Kit (CDK) development and infrastructure as code best practices. This server offers prescriptive patterns using AWS Solutions Constructs, structured decision-making for implementation approaches, and integrated security automation through CDK Nag compliance checks. Features CDK general guidance with best practices, CDK Nag integration for security and compliance rule validation, specialized capabilities for AWS Solutions Constructs discovery, generative AI CDK Constructs search functionality, Lambda Layer documentation provider, and Amazon Bedrock Agent schema generation. Supports infrastructure as code patterns with automated security compliance enforcement, code review for Nag suppressions, and comprehensive CDK project lifecycle management from setup to deployment. Ideal for AWS developers, cloud infrastructure engineers, DevOps professionals, and AI/ML solution architects seeking to implement secure, compliant infrastructure as code using CDK best practices. Requires Python 3.10, uv package manager, AWS CDK CLI, and appropriate AWS credentials. Provides visual workflow diagrams for CDK implementation covering project setup, development, security checks, and deployment processes.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.cdk-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["cdk_guidance", "infrastructure_as_code", "security_compliance", "cdk_nag_integration", "solutions_constructs", "lambda_layers", "bedrock_schemas"],
      "domains": ["aws", "cdk", "infrastructure", "iac", "security"],
      "keywords": ["aws", "mcp", "cdk", "infrastructure-as-code", "security", "compliance", "nag", "constructs"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Install AWS CDK CLI: npm install -g aws-cdk\\n4. Configure AWS credentials: aws configure\\n5. Optional user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n6. Ensure IAM permissions for CDK operations:\\n   - cloudformation:* (for stack operations)\\n   - iam:* (for role management)\\n   - s3:* (for CDK assets)\\n   - ssm:* (for parameter access)\\n7. Initialize CDK project if needed: cdk init\\n8. Test CDK environment: cdk doctor"
    },
    {
      "id": 11,
      "server_id": "awslabs.lambda-tool-mcp-server",
      "name": "AWS Lambda Tool MCP Server",
      "description": "An AWS Labs Model Context Protocol (MCP) server that acts as a secure bridge between MCP clients and AWS Lambda functions, enabling generative AI models to access and execute Lambda functions as extensible tools. This server provides controlled access to private resources and AWS services through Lambda function invocation, implementing segregation of duties and granular access control. Features secure Lambda function discovery via prefixes and tags, function invocation without code changes, access to internal applications and databases through VPC connectivity, interaction with AWS services and public internet resources, and comprehensive input schema validation via EventBridge Schema Registry integration. Supports controlled function execution based on predefined criteria, maintains individual Lambda function resource access permissions, and provides AI models with the ability to use serverless functions as dynamic tools. Ideal for accessing private network resources through AI assistants, executing serverless tools via generative AI, providing secure and controlled function execution, extending AI capabilities with custom Lambda-based tools, and enabling AI-driven automation workflows. Requires Python 3.10, uv package manager, AWS credentials with Lambda invocation permissions, and properly configured Lambda functions with appropriate IAM roles. Essential for organizations seeking to provide AI assistants with secure access to internal systems and custom business logic through serverless functions.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": [
        "awslabs.lambda-tool-mcp-server@latest",
        "--function-prefix",
        "{{env:lambda_function_prefix}}",
        "--region",
        "{{env:lambda_region}}"
      ],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:lambda_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["lambda_invocation", "function_discovery", "schema_validation", "private_resource_access", "serverless_tools", "ai_function_bridge"],
      "domains": ["aws", "lambda", "serverless", "functions", "ai-tools"],
      "keywords": ["aws", "mcp", "lambda", "serverless", "functions", "ai-tools", "bridge", "invocation"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Create Lambda functions with consistent naming prefix\\n5. Configure vault with Lambda details:\\n   - vault set lambda_function_prefix 'your-function-prefix'\\n   - vault set lambda_region 'your-region'\\n6. Optional user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n7. Ensure IAM permissions for Lambda:\\n   - lambda:InvokeFunction\\n   - lambda:ListFunctions\\n   - lambda:GetFunction\\n   - logs:CreateLogGroup\\n   - logs:CreateLogStream\\n   - logs:PutLogEvents\\n8. Test function discovery and invocation"
    },
    {
      "id": 12,
      "server_id": "awslabs.eks-mcp-server",
      "name": "Amazon EKS MCP Server",
      "description": "An AWS Labs Model Context Protocol (MCP) server designed as an AI code assistant tool for managing Amazon Elastic Kubernetes Service (EKS) clusters and Kubernetes resources through intelligent, context-aware interactions. This server enables large language models (LLMs) with essential tooling and contextual awareness to streamline complex Kubernetes operations through natural language interactions. Features comprehensive EKS cluster management with automated infrastructure setup, containerized application deployment support, full Kubernetes resource management (create, read, update, delete operations), log and event retrieval capabilities, intelligent troubleshooting guidance, and seamless CloudWatch integration for metrics and logging. Supports both read-only and write-access modes with granular permissions, implements least-privilege access with AWS authentication, enforces SSL verification, and provides temporary credential generation. Ideal for EKS cluster creation and management, Kubernetes application deployment, cluster monitoring and troubleshooting, development workflow optimization, and AI-assisted infrastructure management. Requires Python 3.10+, uv package manager, and configured AWS CLI credentials. Offers deployment flexibility through Cursor IDE integration, Amazon Q Developer CLI, JSON configuration support, and containerized deployment options. Essential for developers and AI assistants seeking to interact with and manage Kubernetes infrastructure more intelligently and efficiently.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": [
        "awslabs.eks-mcp-server@latest",
        "--cluster-name",
        "{{env:eks_cluster_name}}",
        "--region",
        "{{env:eks_region}}",
        "{{env:eks_write_mode_flag}}"
      ],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:eks_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["eks_management", "kubernetes_resources", "container_deployment", "cluster_monitoring", "cloudwatch_integration", "troubleshooting", "iam_management"],
      "domains": ["aws", "eks", "kubernetes", "containers", "orchestration"],
      "keywords": ["aws", "mcp", "eks", "kubernetes", "containers", "cluster", "deployment", "monitoring"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Install kubectl: curl -LO https://dl.k8s.io/release/v1.28.0/bin/linux/amd64/kubectl\\n4. Configure AWS credentials: aws configure\\n5. Configure vault with EKS details:\\n   - vault set eks_cluster_name 'your-cluster-name'\\n   - vault set eks_region 'your-region'\\n6. Optional user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set eks_write_mode_flag '--write-access' (enables mutations)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n7. Ensure IAM permissions for EKS:\\n   - eks:DescribeCluster\\n   - eks:ListClusters\\n   - eks:AccessKubernetesApi\\n   - cloudwatch:GetMetricData\\n   - logs:DescribeLogGroups\\n   - iam:ListRoles\\n8. Update kubeconfig: aws eks update-kubeconfig --region your-region --name your-cluster\\n9. Test cluster access: kubectl get nodes"
    },
    {
      "id": 13,
      "server_id": "awslabs.cfn-mcp-server",
      "name": "AWS CloudFormation MCP Server",
      "description": "An AWS Labs Model Context Protocol (MCP) server that enables natural language management of 1,100+ AWS resources through AWS Cloud Control API and Infrastructure as Code (IaC) generation capabilities. This server provides a comprehensive interface for declarative infrastructure management, supporting resource creation, reading, updating, deletion, and listing operations through natural language commands. Features resource lifecycle management with validation, CloudFormation template generation capabilities, support for both AWS-native and third-party partner resources, and seamless integration with AWS Cloud Control API for consistent resource management. Offers tools for creating resources declaratively, reading resource properties and attributes, updating existing resources with change validation, deleting resources with safety checks, listing available resources by type, retrieving resource schema information, and generating CloudFormation templates from specifications. Ideal for dynamic infrastructure management, natural language resource provisioning, infrastructure template generation, multi-resource environment setup, and AI-assisted AWS resource management workflows. Requires configured AWS credentials and appropriate IAM permissions for intended resource operations. Supports optional read-only mode for safe exploration and integrates with AWS CloudTrail for auditing. Essential for developers, DevOps engineers, and cloud architects seeking to manage AWS infrastructure through conversational interfaces.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": [
        "awslabs.cfn-mcp-server@latest",
        "{{env:cfn_readonly_flag}}"
      ],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["cloudformation", "infrastructure_as_code", "resource_management", "template_generation", "cloud_control_api", "aws_resources"],
      "domains": ["aws", "cloudformation", "infrastructure", "iac", "resources"],
      "keywords": ["aws", "mcp", "cloudformation", "infrastructure", "iac", "resources", "cloud-control", "templates"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Optional user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set cfn_readonly_flag '--readonly' (enables read-only mode)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n5. Ensure IAM permissions for CloudFormation and Cloud Control API:\\n   - cloudformation:* (for stack operations)\\n   - cloudcontrol:* (for resource management)\\n   - Additional permissions based on managed resources\\n6. Optional: Enable AWS CloudTrail for auditing\\n7. Test connection: aws cloudformation list-stacks"
    },
    {
      "id": 14,
      "server_id": "awslabs.terraform-mcp-server",
      "name": "AWS Terraform MCP Server",
      "description": "An AWS Labs Model Context Protocol (MCP) server that provides comprehensive Terraform best practices guidance and security-first development workflows for AWS infrastructure deployment. This server integrates Checkov security scanning, AWS provider documentation search, and AI/ML infrastructure module support to streamline secure Terraform development. Features prescriptive advice for Terraform configurations on AWS, automated security scanning at development stages, step-by-step guidance for secure infrastructure deployment, analysis capabilities for Terraform Registry modules, and integrated security issue identification with detailed remediation guidance. Supports Terraform and Terragrunt workflow execution, structured development workflows with regular security scanning, emphasis on vulnerability fixing, preference for AWSCC provider with enhanced security defaults, and alignment with AWS Well-Architected framework principles. Ideal for DevOps engineers, cloud architects, infrastructure developers, and security professionals working with AWS who need to implement secure infrastructure as code practices. Requires Python 3.10, uv package manager, Terraform CLI, and Checkov security scanner. Essential for organizations seeking to automate secure Terraform infrastructure development on AWS with integrated guidance, scanning, and compliance validation.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.terraform-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["terraform", "infrastructure_as_code", "security_scanning", "checkov_integration", "aws_provider", "terragrunt", "best_practices"],
      "domains": ["aws", "terraform", "infrastructure", "iac", "security"],
      "keywords": ["aws", "mcp", "terraform", "infrastructure", "iac", "security", "checkov", "terragrunt"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Install Terraform CLI: https://developer.hashicorp.com/terraform/downloads\\n4. Install Checkov: pip install checkov\\n5. Configure AWS credentials: aws configure\\n6. Optional user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n7. Ensure IAM permissions for intended Terraform resources\\n8. Initialize Terraform project: terraform init\\n9. Test Checkov scanning: checkov --help"
    },
    {
      "id": 15,
      "server_id": "awslabs.ecs-mcp-server",
      "name": "AWS ECS MCP Server",
      "description": "An AWS Labs Model Context Protocol (MCP) server designed for containerization and deployment of applications to Amazon Elastic Container Service (ECS) with AI-assisted guidance for the complete containerized application lifecycle. Currently in active development and optimized for non-production environments, this server provides comprehensive containerization guidance, ECS deployment automation, load balancer integration, Infrastructure as Code generation, security best practices implementation, and resource management for both ECS and ECR services. Features tools for generating container configurations, automating AWS infrastructure deployment, checking deployment status and retrieving ALB URLs, removing deployed components safely, listing and managing ECS resources, and diagnosing deployment issues through intelligent troubleshooting. Supports security controls through configurable write permissions and sensitive data access restrictions, with recommendations for dedicated IAM roles using least-privilege permissions. Ideal for development and prototyping environments, learning and exploration of containerized workflows, testing and staging applications, and AI-assisted container lifecycle management. Requires Docker or Finch, UV package manager, Python 3.10+, and properly configured AWS credentials. Not recommended for production workloads or regulated/sensitive applications. Essential for developers and DevOps teams seeking to learn and implement containerized application deployment patterns on AWS ECS with intelligent automation and guidance.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": [
        "awslabs.ecs-mcp-server@latest",
        "{{env:ecs_allow_write_flag}}",
        "{{env:ecs_allow_sensitive_data_flag}}"
      ],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["containerization", "ecs_deployment", "load_balancer_integration", "infrastructure_automation", "ecr_management", "container_troubleshooting"],
      "domains": ["aws", "ecs", "containers", "deployment", "docker"],
      "keywords": ["aws", "mcp", "ecs", "containers", "deployment", "docker", "containerization", "ecr"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Install Docker or Finch for containerization\\n4. Configure AWS credentials: aws configure\\n5. Optional user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set ecs_allow_write_flag '--allow-write' (enables infrastructure changes)\\n   - vault set ecs_allow_sensitive_data_flag '--allow-sensitive-data' (enables sensitive data access)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n6. Ensure IAM permissions for ECS and ECR:\\n   - ecs:* (for cluster and service management)\\n   - ecr:* (for container registry operations)\\n   - iam:* (for role management)\\n   - ec2:* (for VPC and load balancer resources)\\n7. Test Docker/Finch: docker --version\\n8. WARNING: Use only for development/testing, not production workloads"
    },
    {
      "id": 16,
      "server_id": "awslabs.bedrock-kb-retrieval-mcp-server",
      "name": "Amazon Bedrock Knowledge Base Retrieval MCP Server",
      "description": "An AWS Labs Model Context Protocol (MCP) server designed for accessing and querying Amazon Bedrock Knowledge Bases with advanced search capabilities and natural language processing. This server provides knowledge base discovery functionality to find and explore available knowledge bases, search by name or tag, and list associated data sources. Features natural language querying capabilities for retrieving information through conversational queries, extracting relevant passages from knowledge bases, and accessing citation information for results. Supports advanced search capabilities including filtering results by specific data sources, prioritizing or excluding certain data sources, and reranking results using Amazon Bedrock's capabilities. Offers seamless integration with Amazon Bedrock Knowledge Bases, intelligent query translation for semantic search, and comprehensive metadata extraction for enhanced search accuracy. Ideal for enterprise knowledge discovery, semantic search across organizational documents, AI-powered information retrieval, and building intelligent question-answering systems. Requires Python 3.10, AWS CLI configured with Bedrock access, at least one Knowledge Base tagged with 'mcp-multirag-kb=true', and appropriate IAM permissions for listing knowledge bases, accessing data sources, and querying knowledge bases. Essential for organizations seeking to implement AI-driven knowledge management and document discovery workflows.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.bedrock-kb-retrieval-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "BEDROCK_KB_RERANKING_ENABLED": "{{env:bedrock_reranking_enabled}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["AI"],
      "capabilities": ["knowledge_base_search", "natural_language_querying", "document_retrieval", "semantic_search", "citation_extraction", "reranking"],
      "domains": ["aws", "bedrock", "knowledge-base", "search", "ai"],
      "keywords": ["aws", "mcp", "bedrock", "knowledge-base", "semantic-search", "retrieval", "ai", "nlp"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Create and tag Knowledge Bases with 'mcp-multirag-kb=true'\\n5. Optional user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set bedrock_reranking_enabled 'true' (enables reranking)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n6. Ensure IAM permissions for Bedrock:\\n   - bedrock:ListKnowledgeBases\\n   - bedrock:GetKnowledgeBase\\n   - bedrock:QueryKnowledgeBase\\n   - bedrock:ListDataSources\\n7. Test Knowledge Base access: aws bedrock list-knowledge-bases"
    },
    {
      "id": 17,
      "server_id": "awslabs.documentdb-mcp-server",
      "name": "Amazon DocumentDB MCP Server",
      "description": "An AWS Labs Model Context Protocol (MCP) server designed for AWS DocumentDB that enables AI assistants to interact with DocumentDB databases through intelligent, secure, and controlled operations. This server provides comprehensive database interaction capabilities including connection management to DocumentDB clusters, database and collection management operations, document operations for querying and manipulation, aggregation pipeline support for complex data processing, query planning and optimization guidance, and schema analysis for understanding data structures. Features default read-only mode to prevent unintended database modifications, configurable write operations that can be enabled with specific flags, secure TLS connections with certificate support, and granular operation control for enhanced security. Supports MongoDB-compatible operations through DocumentDB's API, intelligent query execution planning, and AI-assisted database exploration capabilities. Ideal for AI-assisted database exploration, secure database interaction in production environments, development and demonstration scenarios, and building intelligent database management workflows. Requires network access to DocumentDB cluster, SSL/TLS certificates for secure connections, and appropriate AWS credentials with DocumentDB permissions. Essential for organizations seeking to implement AI-driven database management and exploration while maintaining strict security controls.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": [
        "awslabs.documentdb-mcp-server@latest",
        "--cluster-endpoint",
        "{{env:documentdb_cluster_endpoint}}",
        "--username",
        "{{env:documentdb_username}}",
        "--password",
        "{{env:documentdb_password}}",
        "{{env:documentdb_allow_write_flag}}"
      ],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:documentdb_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DATA"],
      "capabilities": ["documentdb_access", "mongodb_compatible", "document_operations", "aggregation_pipelines", "schema_analysis", "query_planning"],
      "domains": ["aws", "documentdb", "mongodb", "database", "nosql"],
      "keywords": ["aws", "mcp", "documentdb", "mongodb", "nosql", "database", "documents"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Create DocumentDB cluster in AWS Console\\n4. Download SSL/TLS certificate: wget https://s3.amazonaws.com/rds-downloads/rds-combined-ca-bundle.pem\\n5. Configure vault with DocumentDB details:\\n   - vault set documentdb_cluster_endpoint 'your-cluster-endpoint'\\n   - vault set documentdb_username 'your-username'\\n   - vault set documentdb_password 'your-password'\\n   - vault set documentdb_region 'your-region'\\n6. Optional user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set documentdb_allow_write_flag '--allow-write' (enables mutations)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n7. Ensure network connectivity to DocumentDB cluster\\n8. Test connection with MongoDB client"
    },
    {
      "id": 18,
      "server_id": "awslabs.dynamodb-mcp-server",
      "name": "AWS DynamoDB MCP Server",
      "description": "An AWS Labs Model Context Protocol (MCP) server providing comprehensive DynamoDB interaction capabilities with 30+ operational tools for managing DynamoDB resources, tables, items, queries, backups, and advanced database operations. This server offers complete DynamoDB lifecycle management including design and modeling guidance, table operations (create, delete, update, describe), item operations (get, put, update, delete), query and scan functions with advanced filtering, backup and recovery tools for data protection, Time to Live (TTL) management for automated data cleanup, and export and resource policy operations. Features expert data modeling guidance for optimal schema design, comprehensive API operation mapping for full DynamoDB functionality, automatic credential and region detection for seamless AWS integration, and flexible deployment options including read-only configurations for safe exploration. Supports multiple installation methods and uses standard AWS credential sources for authentication. Ideal for DynamoDB resource management, database design and modeling, operational monitoring and maintenance, development and testing environments, and building scalable NoSQL applications. Requires Python 3.10, AWS credentials with appropriate DynamoDB permissions, and optional configuration for region and profile specifications. Essential for developers and database administrators seeking comprehensive DynamoDB management capabilities through AI-assisted interfaces.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": [
        "awslabs.dynamodb-mcp-server@latest",
        "{{env:dynamodb_readonly_flag}}"
      ],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DATA"],
      "capabilities": ["dynamodb_management", "table_operations", "item_operations", "query_scan", "backup_recovery", "ttl_management", "data_modeling"],
      "domains": ["aws", "dynamodb", "nosql", "database", "serverless"],
      "keywords": ["aws", "mcp", "dynamodb", "nosql", "database", "serverless", "table", "items"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Optional user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set dynamodb_readonly_flag '--readonly' (enables read-only mode)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n5. Ensure IAM permissions for DynamoDB:\\n   - dynamodb:* (for full operations)\\n   - Or specific permissions based on use case\\n6. Test connection: aws dynamodb list-tables"
    },
    {
      "id": 19,
      "server_id": "awslabs.valkey-mcp-server",
      "name": "Amazon ElastiCache/MemoryDB for Valkey MCP Server",
      "description": "An AWS Labs Model Context Protocol (MCP) server for Amazon ElastiCache Valkey datastores, providing comprehensive tools to operate on various Valkey data types including Strings, Lists, Sets, Sorted Sets, Hashes, Streams, Bitmaps, JSONs, and HyperLogLog. Features natural language interaction capabilities for operations like storing user profile data in hashes, adding events to activity streams, and caching API responses with TTL. Supports advanced features including cluster support, SSL/TLS security, connection pooling, and readonly mode option for safe data exploration. Enables AI assistants to efficiently manage data operations through conversational interfaces with built-in retry mechanisms and automatic connection management. Ideal for AI-assisted cache management, data operations automation, and building intelligent caching workflows. Requires network access to Valkey datastore and appropriate AWS credentials for ElastiCache operations.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": [
        "awslabs.valkey-mcp-server@latest",
        "--host",
        "{{env:valkey_host}}",
        "--port",
        "{{env:valkey_port}}",
        "{{env:valkey_readonly_flag}}"
      ],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "VALKEY_SSL": "{{env:valkey_ssl_enabled}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DATA"],
      "capabilities": ["valkey_operations", "cache_management", "data_structures", "cluster_support", "ssl_tls", "connection_pooling"],
      "domains": ["aws", "elasticache", "valkey", "cache", "data-structures"],
      "keywords": ["aws", "mcp", "valkey", "elasticache", "cache", "data-structures", "redis-compatible"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Create or access ElastiCache Valkey cluster\\n4. Configure vault with connection details:\\n   - vault set valkey_host 'your-cluster-endpoint'\\n   - vault set valkey_port '6379'\\n   - vault set valkey_ssl_enabled 'true' (recommended)\\n5. Optional user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set valkey_readonly_flag '--readonly' (enables read-only mode)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n6. Ensure network connectivity to Valkey cluster\\n7. Test connection with Valkey client"
    },
    {
      "id": 20,
      "server_id": "awslabs.memcached-mcp-server",
      "name": "Amazon ElastiCache for Memcached MCP Server",
      "description": "An AWS Labs Model Context Protocol (MCP) server for securely interacting with Amazon ElastiCache Memcached through reliable connections with full support for standard Memcached operations. Features comprehensive Memcached protocol support, secure SSL/TLS communication, automatic connection management with built-in retry mechanisms, and optional readonly mode to prevent write operations for production safety. Supports flexible deployment configurations including local and containerized environments with configurable environment variables. Enables AI assistants to efficiently manage cached data through natural language interfaces while maintaining security best practices. Ideal for cache management automation, development and debugging workflows, and building intelligent caching solutions. Requires network access to Memcached server and appropriate configuration for connection parameters including SSL/TLS settings for secure communication.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": [
        "awslabs.memcached-mcp-server@latest",
        "--host",
        "{{env:memcached_host}}",
        "--port", 
        "{{env:memcached_port}}",
        "{{env:memcached_readonly_flag}}"
      ],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "MEMCACHED_USE_TLS": "{{env:memcached_use_tls}}",
        "MEMCACHED_TIMEOUT": "{{env:memcached_timeout}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DATA"],
      "capabilities": ["memcached_operations", "cache_management", "ssl_tls_support", "automatic_retries", "readonly_mode"],
      "domains": ["aws", "elasticache", "memcached", "cache", "memory"],
      "keywords": ["aws", "mcp", "memcached", "elasticache", "cache", "memory", "key-value"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Create or access ElastiCache Memcached cluster\\n4. Configure vault with connection details:\\n   - vault set memcached_host 'your-cluster-endpoint'\\n   - vault set memcached_port '11211'\\n   - vault set memcached_use_tls 'true' (recommended)\\n   - vault set memcached_timeout '30'\\n5. Optional user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set memcached_readonly_flag '--readonly' (enables read-only mode)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n6. Ensure network connectivity to Memcached cluster\\n7. Test connection with Memcached client"
    },
    {
      "id": 21,
      "server_id": "awslabs.code-doc-gen-mcp-server",
      "name": "AWS Labs Code Documentation Generation MCP Server",
      "description": "An automated documentation generation tool that analyzes repository structure and generates comprehensive documentation for code projects. Features automatic project directory structure analysis, multiple document type generation (README, API docs, backend/frontend docs), structured documentation based on project type, and integration with AWS Diagram and CDK MCP servers. Supports core workflow including repository analysis preparation, documentation context creation, documentation structure planning, and document template generation. Ideal for automated documentation workflows, project documentation standardization, and developer productivity enhancement. Requires Python 3.10, uv package manager, and repomix for repository analysis.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "PUBLIC",
      "command": "uvx",
      "args": ["awslabs.code-doc-gen-mcp-server@latest"],
      "env": {
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["documentation_generation", "repository_analysis", "project_structure_analysis", "template_generation", "automated_docs"],
      "domains": ["documentation", "code-analysis", "automation", "development"],
      "keywords": ["aws", "mcp", "documentation", "code-analysis", "automation", "repomix", "templates"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Install repomix: npm install -g repomix@^0.2.6\\n4. Optional user preferences:\\n   - vault set log_level 'ERROR' (default: ERROR)\\n5. Navigate to your project directory\\n6. Run the server to analyze and generate documentation\\n7. No AWS credentials required for basic functionality"
    },
    {
      "id": 22,
      "server_id": "awslabs.core-mcp-server",
      "name": "AWS Labs Core MCP Server",
      "description": "An orchestration MCP server that provides a starting point for using various AWS-related MCP servers with integrated prompt understanding and translation to AWS services. Features planning and orchestration capabilities for AWS solutions, prompt understanding tool for guidance and planning support, and seamless integration with multiple AWS MCP servers including AWS API, CDK, Bedrock KB Retrieval, Nova Canvas, AWS Pricing, AWS Documentation, and AWS Diagram servers. Supports comprehensive AWS solution planning with intelligent guidance for building cloud architectures. Ideal for AWS solution orchestration, multi-service planning workflows, and providing intelligent guidance when building complex AWS solutions. Requires Python 3.12+, uv package manager, AWS credentials with Bedrock access, and Node.js for full functionality.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.core-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["aws_orchestration", "prompt_understanding", "solution_planning", "multi_service_integration", "guidance_planning"],
      "domains": ["aws", "orchestration", "planning", "integration"],
      "keywords": ["aws", "mcp", "core", "orchestration", "planning", "bedrock", "guidance"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.12+: uv python install 3.12\\n3. Install Node.js: https://nodejs.org/\\n4. Configure AWS credentials with Bedrock access: aws configure\\n5. Optional user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n6. Ensure IAM permissions for AWS Bedrock\\n7. Test Bedrock access: aws bedrock list-foundation-models"
    },
    {
      "id": 23,
      "server_id": "awslabs.cost-explorer-mcp-server",
      "name": "AWS Cost Explorer MCP Server",
      "description": "An AWS cost analysis and management tool that enables natural language querying of cloud spending data with comprehensive cost analytics capabilities. Features AWS cost analysis by service, region, and dimensions, cost comparison between time periods, cost forecast generation, and natural language cost data querying. Provides tools for retrieving dimension values, tag values, cost and usage data, cost comparisons, comparison drivers analysis, and cost forecasting. Supports complex cost analytics including service-based cost analysis, regional spending breakdown, time-based cost comparisons, and predictive cost modeling. Ideal for cloud cost optimization, financial reporting and analysis, budget planning and forecasting, and AI-assisted cost management workflows. Requires Python 3.10, uv package manager, and AWS credentials with Cost Explorer API access. Note: Each Cost Explorer API request costs $0.01, and complex queries may generate multiple billable requests.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.cost-explorer-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["cost_analysis", "financial_reporting", "cost_forecasting", "usage_analytics", "budget_management", "natural_language_querying"],
      "domains": ["aws", "cost-management", "analytics", "financial"],
      "keywords": ["aws", "mcp", "cost-explorer", "billing", "analytics", "forecasting", "financial"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Optional user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n5. Ensure IAM permissions for Cost Explorer API:\\n   - ce:GetCostAndUsage\\n   - ce:GetDimensionValues\\n   - ce:GetUsageForecast\\n   - ce:GetCostAndUsageWithResources\\n6. Test Cost Explorer access: aws ce get-cost-and-usage --help\\n7. WARNING: Each API request costs $0.01"
    },
    {
      "id": 24,
      "server_id": "awslabs.finch-mcp-server",
      "name": "AWS Labs Finch MCP Server",
      "description": "A Model Context Protocol (MCP) server for Finch that enables generative AI models to build and push container images through finch CLI leveraged MCP tools. Features container image building using Finch, pushing container images to repositories including Amazon ECR, ECR repository checking and creation, automatic Finch VM initialization management, and ECR credential helpers configuration. Supports two operation modes: default read-only mode to prevent creating new AWS resources, and write mode that enables AWS resource creation with the --enable-aws-resource-write flag. Ideal for containerized application development, ECR integration workflows, and AI-assisted container image management. Requires Python 3.10, uv package manager, Finch installation, and AWS credentials with ECR permissions for pushing and creating repositories.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.finch-mcp-server@latest", "{{env:finch_enable_write_flag}}"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["container_building", "ecr_integration", "finch_management", "image_pushing", "repository_management"],
      "domains": ["aws", "finch", "containers", "ecr", "docker"],
      "keywords": ["aws", "mcp", "finch", "containers", "ecr", "docker", "images"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Install Finch: https://github.com/runfinch/finch\\n4. Configure AWS credentials: aws configure\\n5. Optional user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set finch_enable_write_flag '--enable-aws-resource-write' (enables AWS resource creation)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n6. Ensure IAM permissions for ECR:\\n   - ecr:GetAuthorizationToken\\n   - ecr:BatchCheckLayerAvailability\\n   - ecr:InitiateLayerUpload\\n   - ecr:UploadLayerPart\\n   - ecr:CompleteLayerUpload\\n   - ecr:PutImage\\n   - ecr:CreateRepository\\n   - ecr:DescribeRepositories\\n7. Test Finch: finch version"
    },
    {
      "id": 25,
      "server_id": "awslabs.frontend-mcp-server",
      "name": "AWS Labs Frontend MCP Server",
      "description": "A Model Context Protocol (MCP) server that provides specialized tools for modern web application development with comprehensive guidance on React application development and AWS integration. Features documentation and guidance on essential React knowledge, UI setup with Tailwind CSS, AWS Amplify authentication integration, React Router implementation, component creation best practices, and troubleshooting workflows. Provides the GetReactDocsByTopic tool for retrieving documentation on specific React and AWS integration topics including essential knowledge and troubleshooting guides. Ideal for frontend development workflows, React application guidance, AWS Amplify integration, and developer education and support. Requires Python 3.10, uv package manager, and MCP client configuration. No AWS credentials required for basic documentation access.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "PUBLIC",
      "command": "uvx",
      "args": ["awslabs.frontend-mcp-server@latest"],
      "env": {
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["react_documentation", "frontend_guidance", "amplify_integration", "ui_development", "troubleshooting_support"],
      "domains": ["frontend", "react", "amplify", "tailwind", "web-development"],
      "keywords": ["aws", "mcp", "frontend", "react", "amplify", "tailwind", "ui", "web"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Optional user preferences:\\n   - vault set log_level 'ERROR' (default: ERROR)\\n4. Configure MCP server in your MCP client\\n5. No AWS credentials required for basic functionality\\n6. Access documentation topics like 'essential-knowledge' and 'troubleshooting'"
    },
    {
      "id": 26,
      "server_id": "awslabs.git-repo-research-mcp-server",
      "name": "AWS Labs Git Repo Research MCP Server",
      "description": "A Model Context Protocol (MCP) server for researching Git repositories using semantic search powered by Amazon Bedrock and FAISS indexing. Features repository indexing using FAISS and Amazon Bedrock embeddings, semantic search of repository content, GitHub repository discovery with scoped search (default: AWS organizations), file and directory access, and repository summary generation. Supports both local and remote repository indexing with intelligent semantic search capabilities for code discovery and analysis. Ideal for code research and discovery, repository analysis workflows, semantic code search, and AI-assisted repository exploration. Requires Python 3.12, uv package manager, AWS credentials with Bedrock access, and optional GitHub token for higher rate limits. Note: Large repositories may require significant indexing time and binary file support is limited.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.git-repo-research-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "GITHUB_TOKEN": "{{env:github_token}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["semantic_search", "repository_indexing", "github_discovery", "code_analysis", "repository_research"],
      "domains": ["git", "github", "repository", "semantic-search", "code-analysis"],
      "keywords": ["aws", "mcp", "git", "github", "semantic-search", "bedrock", "faiss", "repository"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.12: uv python install 3.12\\n3. Configure AWS credentials with Bedrock access: aws configure\\n4. Optional GitHub token for higher rate limits:\\n   - vault set github_token 'your-github-token'\\n5. Configure user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n6. Ensure IAM permissions for Amazon Bedrock:\\n   - bedrock:InvokeModel\\n   - bedrock:ListFoundationModels\\n7. Test Bedrock access: aws bedrock list-foundation-models"
    },
    {
      "id": 27,
      "server_id": "awslabs.elasticache-mcp-server",
      "name": "AWS ElastiCache MCP Server",
      "description": "The official MCP Server for interacting with AWS ElastiCache control plane with comprehensive cache management capabilities. Features serverless cache operations, replication group management, cache cluster management, CloudWatch and CloudWatch Logs monitoring integration, Cost Explorer integration, and service update management. Supports read-only mode to prevent resource modifications, automatic AWS authentication and connection management, and configurable retry and timeout settings. Provides comprehensive ElastiCache API interaction for managing Redis and Memcached clusters. Ideal for cache infrastructure management, performance monitoring, and AI-assisted ElastiCache operations. Requires Python 3.10, uv package manager, and AWS credentials with ElastiCache permissions.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.elasticache-mcp-server@latest", "{{env:elasticache_readonly_flag}}"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DATA"],
      "capabilities": ["elasticache_management", "cache_monitoring", "replication_groups", "cluster_management", "cost_analysis", "service_updates"],
      "domains": ["aws", "elasticache", "cache", "redis", "memcached"],
      "keywords": ["aws", "mcp", "elasticache", "cache", "redis", "memcached", "clustering"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Optional user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set elasticache_readonly_flag '--readonly' (enables read-only mode)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n5. Ensure IAM permissions for ElastiCache:\\n   - elasticache:Describe*\\n   - elasticache:List*\\n   - cloudwatch:GetMetricData\\n   - logs:DescribeLogGroups\\n6. Test ElastiCache access: aws elasticache describe-cache-clusters"
    },
    {
      "id": 28,
      "server_id": "awslabs.iam-mcp-server",
      "name": "AWS IAM MCP Server",
      "description": "A Model Context Protocol (MCP) server for comprehensive AWS Identity and Access Management (IAM) operations with extensive user, role, group, and policy management capabilities. Features user management (list, create, delete users), role management (list, create roles), group management (list, add/remove users, manage policies), policy management and simulation, access key management, and read-only mode for safe exploration. Supports AWS IAM security best practices with comprehensive permission management and policy simulation capabilities. Ideal for IAM administration, security auditing, access management workflows, and AI-assisted identity governance. Requires extensive IAM permissions for full functionality with optional read-only mode for safe exploration.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.iam-mcp-server@latest", "{{env:iam_readonly_flag}}"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["iam_management", "user_management", "role_management", "policy_management", "access_key_management", "security_auditing"],
      "domains": ["aws", "iam", "security", "access-management", "identity"],
      "keywords": ["aws", "mcp", "iam", "security", "users", "roles", "policies", "access-management"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Optional user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set iam_readonly_flag '--readonly' (enables read-only mode, recommended)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n5. Ensure IAM permissions (extensive permissions required):\\n   - iam:List* (for read operations)\\n   - iam:Get* (for detailed information)\\n   - iam:Create* (for write operations, if not read-only)\\n   - iam:Delete* (for deletion operations, if not read-only)\\n6. WARNING: Use with caution, especially in production environments"
    },
    {
      "id": 29,
      "server_id": "awslabs.mcp-lambda-handler",
      "name": "AWS Labs MCP Lambda Handler Module",
      "description": "A Python library for creating serverless HTTP handlers for the Model Context Protocol (MCP) using AWS Lambda with easy serverless MCP HTTP handler creation and pluggable session management. Features NoOp, DynamoDB, or custom session management backends, supports Python 3.10+, and provides flexible authentication and session management. Supports typical serverless architecture with API Gateway, Lambda Authorizer, MCP Server Lambda, and optional DynamoDB for session storage. Ideal for serverless MCP deployments, Lambda-based MCP servers, scalable MCP architectures, and cloud-native MCP implementations. Requires Python 3.10+, core dependencies including python-dateutil, and optional AWS dependencies (boto3, botocore) for AWS integration.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "pip",
      "args": ["install", "awslabs.mcp-lambda-handler"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["serverless_mcp", "lambda_handlers", "session_management", "http_handlers", "dynamodb_integration"],
      "domains": ["aws", "lambda", "serverless", "mcp", "http"],
      "keywords": ["aws", "mcp", "lambda", "serverless", "http", "handlers", "session-management"],
      "setup_instructions": "1. Install Python 3.10+\\n2. Install the library: pip install awslabs.mcp-lambda-handler\\n3. Optional AWS dependencies: pip install boto3 botocore\\n4. Configure AWS credentials: aws configure\\n5. Set up API Gateway and Lambda for serverless deployment\\n6. Optional: Configure DynamoDB for session storage\\n7. Implement MCP server logic using the provided handler framework\\n8. Deploy to AWS Lambda with appropriate IAM permissions"
    },
    {
      "id": 30,
      "server_id": "awslabs.nova-canvas-mcp-server",
      "name": "Amazon Nova Canvas MCP Server",
      "description": "An MCP server for generating images using Amazon Nova Canvas with comprehensive text-based and color-guided image generation capabilities. Features text-based image generation from prompts with customizable dimensions (320-4096px), support for multiple image generation (1-5 images), and adjustable generation parameters. Includes color-guided image generation with specific color palettes (up to 10 hex color values) to influence image style and mood. Provides workspace integration with automatic image saving to specified directories and AWS authentication using AWS profiles for secure access. Ideal for AI-powered image generation workflows, creative content creation, and automated visual asset generation. Requires Python 3.10, uv package manager, and AWS credentials with Amazon Bedrock and Nova Canvas permissions.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.nova-canvas-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "WORKSPACE_DIR": "{{env:workspace_directory}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["AI"],
      "capabilities": ["image_generation", "text_to_image", "color_guided_generation", "workspace_integration", "nova_canvas"],
      "domains": ["aws", "bedrock", "nova-canvas", "image-generation", "ai"],
      "keywords": ["aws", "mcp", "nova-canvas", "image-generation", "bedrock", "ai", "text-to-image"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials with Bedrock access: aws configure\\n4. Configure user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set workspace_directory '/path/to/save/images'\\n   - vault set log_level 'ERROR' (default: ERROR)\\n5. Ensure IAM permissions for Amazon Bedrock and Nova Canvas:\\n   - bedrock:InvokeModel\\n   - bedrock:ListFoundationModels\\n6. Test Bedrock access: aws bedrock list-foundation-models\\n7. Alternative installation via Smithery: npx -y @smithery/cli install @awslabs/nova-canvas-mcp-server"
    },
    {
      "id": 31,
      "server_id": "awslabs.openapi-mcp-server",
      "name": "AWS Labs OpenAPI MCP Server",
      "description": "A server that dynamically creates Model Context Protocol (MCP) tools and resources from OpenAPI specifications with comprehensive API integration capabilities. Features automatic MCP tool generation from API endpoints, operation-specific and API documentation prompt creation, support for multiple authentication methods, and dynamic tool generation for Large Language Models. Provides comprehensive metrics and logging, OpenAPI specification validation, intelligent route mapping, prompt optimization, and AWS best practices implementation. Supports stdio transport with configurable environment variables. Ideal for API integration workflows, dynamic tool generation, automated API documentation, and AI-assisted API interaction. Requires OpenAPI specification URL or local file path, API name and base URL configuration, and optional authentication setup.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "PUBLIC",
      "command": "pip",
      "args": ["install", "awslabs.openapi-mcp-server"],
      "env": {
        "API_NAME": "{{env:api_name}}",
        "API_BASE_URL": "{{env:api_base_url}}",
        "OPENAPI_SPEC_URL": "{{env:openapi_spec_url}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["openapi_integration", "dynamic_tool_generation", "api_documentation", "authentication_support", "route_mapping"],
      "domains": ["api", "openapi", "integration", "documentation", "tools"],
      "keywords": ["aws", "mcp", "openapi", "api", "integration", "tools", "documentation"],
      "setup_instructions": "1. Install via pip: pip install awslabs.openapi-mcp-server\\n2. Configure required parameters:\\n   - vault set api_name 'your-api-name'\\n   - vault set api_base_url 'https://your-api-base-url'\\n   - vault set openapi_spec_url 'https://url-to-openapi-spec' (or local file path)\\n3. Optional user preferences:\\n   - vault set log_level 'ERROR' (default: ERROR)\\n4. Configure authentication if required by your API\\n5. Set stdio transport option in MCP client\\n6. Test with a simple API specification"
    },
    {
      "id": 32,
      "server_id": "awslabs.prometheus-mcp-server",
      "name": "AWS Labs Prometheus MCP Server",
      "description": "The Prometheus MCP Server provides a robust interface for interacting with AWS Managed Prometheus, enabling users to execute PromQL queries, list metrics, and retrieve server information with AWS SigV4 authentication support. Features execution of instant and range PromQL queries, listing of available metrics, server configuration information retrieval, AWS SigV4 authentication, and automatic retries with exponential backoff. Supports comprehensive Prometheus monitoring and metrics analysis through AWS Managed Prometheus workspace integration. Ideal for monitoring and observability workflows, metrics analysis and querying, AWS Managed Prometheus integration, and AI-assisted monitoring operations. Requires Python 3.10+, AWS credentials with appropriate permissions, and AWS Managed Prometheus workspace access.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.prometheus-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "PROMETHEUS_WORKSPACE_ID": "{{env:prometheus_workspace_id}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["prometheus_querying", "metrics_analysis", "promql_execution", "aws_managed_prometheus", "monitoring"],
      "domains": ["aws", "prometheus", "monitoring", "metrics", "observability"],
      "keywords": ["aws", "mcp", "prometheus", "monitoring", "metrics", "promql", "observability"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Set up AWS Managed Prometheus workspace\\n5. Configure user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set prometheus_workspace_id 'your-workspace-id'\\n   - vault set log_level 'ERROR' (default: ERROR)\\n6. Ensure IAM permissions for AWS Managed Prometheus:\\n   - aps:QueryMetrics\\n   - aps:GetSeries\\n   - aps:GetLabels\\n   - aps:GetMetricMetadata\\n7. Test Prometheus access: aws amp list-workspaces"
    },
    {
      "id": 33,
      "server_id": "awslabs.redshift-mcp-server",
      "name": "Amazon Redshift MCP Server",
      "description": "A Model Context Protocol (MCP) server for Amazon Redshift that enables AI assistants to interact with Redshift resources safely and efficiently with comprehensive data warehouse management capabilities. Features cluster discovery to automatically find Redshift clusters and serverless workgroups, metadata exploration to browse databases, schemas, tables, and columns, safe query execution in READ ONLY mode, and multi-cluster support to work with multiple clusters simultaneously. Provides secure and controlled access to Redshift data warehouses with intelligent query execution and metadata discovery. Ideal for data warehouse analytics, business intelligence workflows, data exploration and discovery, and AI-assisted data analysis. Requires Python 3.10+, AWS credentials, IAM permissions for Redshift operations, and database-level permissions for data access.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.redshift-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "REDSHIFT_CLUSTER_IDENTIFIER": "{{env:redshift_cluster_id}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DATA"],
      "capabilities": ["redshift_querying", "cluster_discovery", "metadata_exploration", "data_warehouse_access", "multi_cluster_support"],
      "domains": ["aws", "redshift", "data-warehouse", "analytics", "sql"],
      "keywords": ["aws", "mcp", "redshift", "data-warehouse", "analytics", "sql", "bi"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Configure user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set redshift_cluster_id 'your-cluster-identifier'\\n   - vault set log_level 'ERROR' (default: ERROR)\\n5. Ensure IAM permissions for Redshift:\\n   - redshift:DescribeClusters\\n   - redshift-serverless:ListWorkgroups\\n   - redshift-data:ExecuteStatement\\n   - redshift-data:GetStatementResult\\n6. Ensure database permissions:\\n   - SELECT on tables\\n   - USAGE on schemas\\n   - Database connection access\\n7. Test Redshift access: aws redshift describe-clusters"
    },
    {
      "id": 34,
      "server_id": "awslabs.s3-tables-mcp-server",
      "name": "AWS S3 Tables MCP Server",
      "description": "An AWS Labs Model Context Protocol (MCP) server for AWS S3 Tables that enables AI assistants to interact with S3-based table storage with comprehensive table management capabilities. Features table bucket management, namespace management, table management, metadata management, read-only SQL query support, CSV to table conversion, and metadata discovery. Supports secure table operations with default read-only mode and optional write operations via --allow-write flag. Provides intelligent S3-based table storage management with metadata discovery and query capabilities. Ideal for S3 table analytics, data lake table management, metadata exploration, and AI-assisted table operations. Requires Python 3.10, uv package manager, and AWS credentials with appropriate S3 Tables permissions.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.s3-tables-mcp-server@latest", "{{env:s3_tables_allow_write_flag}}"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DATA"],
      "capabilities": ["s3_tables_management", "table_bucket_management", "namespace_management", "metadata_discovery", "sql_querying", "csv_conversion"],
      "domains": ["aws", "s3", "tables", "data-lake", "analytics"],
      "keywords": ["aws", "mcp", "s3-tables", "data-lake", "analytics", "metadata", "sql"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Configure user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set s3_tables_allow_write_flag '--allow-write' (enables write operations)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n5. Ensure IAM permissions for S3 Tables:\\n   - s3tables:GetTableBucket\\n   - s3tables:ListTableBuckets\\n   - s3tables:GetNamespace\\n   - s3tables:ListNamespaces\\n   - s3tables:GetTable\\n   - s3tables:ListTables\\n   - Additional permissions for write operations if enabled\\n6. Test S3 Tables access\\n7. WARNING: Review permissions carefully when enabling write operations"
    },
    {
      "id": 35,
      "server_id": "awslabs.stepfunctions-tool-mcp-server",
      "name": "AWS Step Functions Tool MCP Server",
      "description": "A Model Context Protocol (MCP) server for AWS Step Functions to select and run state machines as MCP tools without code changes. Features bridging between MCP clients and AWS Step Functions state machines, support for Standard and Express workflows, EventBridge Schema Registry integration for input validation, comprehensive tool documentation generation, and IAM-based authentication and authorization. State machines handle AWS service interactions using their own IAM roles, maintaining robust security boundaries. Ideal for workflow orchestration, serverless automation, AI-assisted state machine execution, and process automation workflows. Requires Python 3.10, uv package manager, and AWS credentials with Step Functions permissions.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.stepfunctions-tool-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "STATE_MACHINE_PREFIX": "{{env:stepfunctions_prefix}}",
        "STATE_MACHINE_LIST": "{{env:stepfunctions_list}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["stepfunctions_execution", "workflow_orchestration", "state_machine_management", "schema_validation", "express_workflows"],
      "domains": ["aws", "stepfunctions", "workflows", "orchestration", "automation"],
      "keywords": ["aws", "mcp", "stepfunctions", "workflows", "state-machines", "orchestration", "automation"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Configure user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set stepfunctions_prefix 'your-state-machine-prefix'\\n   - vault set stepfunctions_list 'comma-separated-state-machine-names'\\n   - vault set log_level 'ERROR' (default: ERROR)\\n5. Ensure IAM permissions for Step Functions:\\n   - states:ListStateMachines\\n   - states:DescribeStateMachine\\n   - states:StartExecution\\n   - states:DescribeExecution\\n   - events:ListSchemas (for EventBridge Schema Registry)\\n6. Test Step Functions access: aws stepfunctions list-state-machines"
    },
    {
      "id": 36,
      "server_id": "awslabs.syntheticdata-mcp-server",
      "name": "AWS Labs Synthetic Data MCP Server",
      "description": "A Model Context Protocol (MCP) server for generating, validating, and managing synthetic data with comprehensive business-driven data generation capabilities. Features business-driven synthetic data generation, safe pandas code execution, data validation and referential integrity checking, storage integration with S3 and multiple file formats, and data quality assessment. Generates data generation instructions from business descriptions, validates data structures, and supports loading data to different storage targets with configuration options. Ideal for data testing and development, synthetic dataset creation, data privacy compliance, and AI training data generation. Requires Python 3.10, uv package manager, and AWS credentials with S3 access for storage integration.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.syntheticdata-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "SYNTHETIC_DATA_BUCKET": "{{env:synthetic_data_bucket}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DATA"],
      "capabilities": ["synthetic_data_generation", "data_validation", "pandas_execution", "s3_integration", "data_quality_assessment"],
      "domains": ["data-generation", "synthetic-data", "testing", "privacy"],
      "keywords": ["aws", "mcp", "synthetic-data", "data-generation", "testing", "pandas", "validation"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Configure user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set synthetic_data_bucket 'your-s3-bucket-for-storage'\\n   - vault set log_level 'ERROR' (default: ERROR)\\n5. Ensure IAM permissions for S3 and data operations:\\n   - s3:GetObject\\n   - s3:PutObject\\n   - s3:DeleteObject\\n   - s3:ListBucket\\n6. Create S3 bucket for synthetic data storage\\n7. Test S3 access: aws s3 ls s3://your-bucket-name"
    },
    {
      "id": 37,
      "server_id": "awslabs.timestream-for-influxdb-mcp-server",
      "name": "AWS Labs Timestream for InfluxDB MCP Server",
      "description": "An AWS Labs Model Context Protocol (MCP) server for Timestream for InfluxDB that provides comprehensive tools to interact with AWS Timestream for InfluxDB APIs. Features database cluster management (create, update, list, describe, delete), database instance management, parameter group management, tag management (list, add, remove tags), and InfluxDB data operations including writing data points and Line Protocol and querying data using Flux query language. Provides complete lifecycle management for Timestream for InfluxDB resources with secure access controls. Ideal for time-series data management, IoT data analytics, monitoring and observability, and AI-assisted time-series operations. Requires Python 3.10, uv package manager, and AWS credentials with Timestream for InfluxDB permissions.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.timestream-for-influxdb-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "TIMESTREAM_CLUSTER_IDENTIFIER": "{{env:timestream_cluster_id}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DATA"],
      "capabilities": ["timestream_management", "influxdb_operations", "cluster_management", "time_series_querying", "tag_management", "flux_queries"],
      "domains": ["aws", "timestream", "influxdb", "time-series", "iot"],
      "keywords": ["aws", "mcp", "timestream", "influxdb", "time-series", "iot", "flux", "monitoring"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Configure user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set timestream_cluster_id 'your-cluster-identifier'\\n   - vault set log_level 'ERROR' (default: ERROR)\\n5. Ensure IAM permissions for Timestream for InfluxDB:\\n   - timestream-influxdb:DescribeDbCluster\\n   - timestream-influxdb:ListDbClusters\\n   - timestream-influxdb:DescribeDbInstance\\n   - timestream-influxdb:ListDbInstances\\n   - timestream-influxdb:CreateDbCluster\\n   - timestream-influxdb:DeleteDbCluster\\n6. Start with read-only permissions and expand as needed\\n7. Test Timestream access: aws timestream-influxdb list-db-clusters"
    },
    {
      "id": 38,
      "server_id": "awslabs.amazon-kendra-index-mcp-server",
      "name": "Amazon Kendra Index MCP Server",
      "description": "An AWS Labs Model Context Protocol (MCP) server for Amazon Kendra that allows using Kendra Indices as additional context for Retrieval-Augmented Generation (RAG) with enhanced chatbot capabilities. Features chatbot enhancement with additional RAG indices, improved responses from coding assistants, and comprehensive querying and listing of Amazon Kendra Indexes. Provides tools for querying Kendra index for context and listing Kendra Indexes in account. Follows the principle of least privilege when setting up IAM permissions for secure access control. Ideal for RAG-enhanced applications, knowledge retrieval workflows, chatbot context enhancement, and AI-assisted information discovery. Requires AWS account, Amazon Kendra Index, Python 3.10, uv package manager, and IAM permissions for Kendra access.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.amazon-kendra-index-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "KENDRA_INDEX_ID": "{{env:kendra_index_id}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["AI"],
      "capabilities": ["kendra_querying", "rag_enhancement", "knowledge_retrieval", "index_listing", "context_enhancement"],
      "domains": ["aws", "kendra", "search", "rag", "knowledge"],
      "keywords": ["aws", "mcp", "kendra", "rag", "search", "knowledge", "retrieval"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Create Amazon Kendra Index in AWS Console\\n4. Configure AWS credentials: aws configure\\n5. Configure user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set kendra_index_id 'your-kendra-index-id'\\n   - vault set log_level 'ERROR' (default: ERROR)\\n6. Ensure IAM permissions for Kendra (least privilege):\\n   - kendra:Query\\n   - kendra:ListIndices\\n   - kendra:DescribeIndex\\n7. Test Kendra access: aws kendra list-indices"
    },
    {
      "id": 39,
      "server_id": "awslabs.amazon-keyspaces-mcp-server",
      "name": "Amazon Keyspaces MCP Server",
      "description": "An Amazon Keyspaces (for Apache Cassandra) MCP server for interacting with Amazon Keyspaces and Apache Cassandra with comprehensive database exploration and querying capabilities. Features database schema exploration, read-only SELECT query execution, query performance analysis, and compatibility with both Amazon Keyspaces and Apache Cassandra. Enables AI assistants like Amazon Q to interact with databases through natural language queries with intelligent query translation and performance optimization. Ideal for Cassandra database analytics, schema exploration, performance analysis, and AI-assisted database querying. Requires Python 3.10 or 3.11, access to Cassandra/Keyspaces database, Cassandra login credentials, and Starfield digital certificate for Amazon Keyspaces.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "pip",
      "args": ["install", "awslabs.amazon-keyspaces-mcp-server"],
      "env": {
        "KEYSPACES_ENDPOINT": "{{env:keyspaces_endpoint}}",
        "KEYSPACES_USERNAME": "{{env:keyspaces_username}}",
        "KEYSPACES_PASSWORD": "{{env:keyspaces_password}}",
        "AWS_REGION": "{{env:aws_region}}"
      },
      "categories": ["DATA"],
      "capabilities": ["keyspaces_querying", "schema_exploration", "cassandra_compatibility", "performance_analysis", "natural_language_queries"],
      "domains": ["aws", "keyspaces", "cassandra", "database", "nosql"],
      "keywords": ["aws", "mcp", "keyspaces", "cassandra", "nosql", "database", "schema"],
      "setup_instructions": "1. Install Python 3.10 or 3.11\\n2. Install the server: pip install awslabs.amazon-keyspaces-mcp-server\\n3. Create Amazon Keyspaces cluster or access existing Cassandra database\\n4. Download Starfield certificate for Amazon Keyspaces (if using Keyspaces)\\n5. Configure connection details:\\n   - vault set keyspaces_endpoint 'your-keyspaces-endpoint'\\n   - vault set keyspaces_username 'your-username'\\n   - vault set keyspaces_password 'your-password'\\n   - vault set aws_region 'your-region'\\n6. Ensure network connectivity to Keyspaces/Cassandra\\n7. Test connection with cqlsh or similar tool"
    },
    {
      "id": 40,
      "server_id": "awslabs.amazon-mq-mcp-server",
      "name": "Amazon MQ MCP Server",
      "description": "A Model Context Protocol (MCP) server for Amazon MQ that enables generative AI models to manage RabbitMQ and ActiveMQ message brokers with comprehensive broker management capabilities. Features creation and management of Amazon MQ brokers, broker settings configuration, listing and describing existing brokers, broker rebooting and updating, creation and management of broker configurations, and automatic resource tagging for security. Provides secure interaction with Amazon MQ resources through resource tagging to prevent unauthorized modifications. Ideal for message broker management, queue infrastructure automation, broker configuration management, and AI-assisted messaging workflows. Requires Python 3.10, uv package manager, and AWS account with permissions to create and manage Amazon MQ resources.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.amazon-mq-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["mq_broker_management", "broker_configuration", "rabbitmq_support", "activemq_support", "resource_tagging"],
      "domains": ["aws", "mq", "messaging", "rabbitmq", "activemq"],
      "keywords": ["aws", "mcp", "mq", "messaging", "rabbitmq", "activemq", "brokers"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Configure user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n5. Ensure IAM permissions for Amazon MQ:\\n   - mq:CreateBroker\\n   - mq:DeleteBroker\\n   - mq:DescribeBroker\\n   - mq:ListBrokers\\n   - mq:UpdateBroker\\n   - mq:RebootBroker\\n   - mq:CreateConfiguration\\n   - mq:ListConfigurations\\n6. Test MQ access: aws mq list-brokers"
    },
    {
      "id": 41,
      "server_id": "awslabs.amazon-neptune-mcp-server",
      "name": "Amazon Neptune MCP Server",
      "description": "An Amazon Neptune MCP server that allows for comprehensive graph database management with fetching status, schema, and querying using openCypher and Gremlin for Neptune Database and openCypher for Neptune Analytics. Features query execution with openCypher and/or Gremlin queries, graph schema retrieval as text string, and status checking to determine if graph is Available or Unavailable. Supports both Neptune Database and Neptune Analytics with flexible query language support. Ideal for graph database analytics, knowledge graph exploration, relationship analysis, and AI-assisted graph querying. Requires Python 3.10, uv package manager, AWS CLI configured with credentials, IAM permissions for Neptune access, and network access to Neptune instance.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.amazon-neptune-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "NEPTUNE_ENDPOINT": "{{env:neptune_endpoint}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DATA"],
      "capabilities": ["neptune_querying", "graph_schema_analysis", "opencypher_queries", "gremlin_queries", "status_monitoring"],
      "domains": ["aws", "neptune", "graph-database", "analytics", "knowledge-graph"],
      "keywords": ["aws", "mcp", "neptune", "graph", "opencypher", "gremlin", "analytics"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Create or access Neptune Database/Analytics cluster\\n5. Configure user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set neptune_endpoint 'your-neptune-endpoint'\\n   - vault set log_level 'ERROR' (default: ERROR)\\n6. Ensure IAM permissions for Neptune:\\n   - neptune-db:QueryStatus\\n   - neptune-db:ReadDataViaQuery\\n   - neptune-db:GetStatistics\\n7. Ensure network access to Neptune instance\\n8. Test Neptune access: curl https://your-neptune-endpoint:8182/status"
    },
    {
      "id": 42,
      "server_id": "awslabs.amazon-qbusiness-anonymous-mcp-server",
      "name": "AWS Labs Amazon Q Business Anonymous MCP Server",
      "description": "An AWS Labs Model Context Protocol (MCP) server for Amazon Q Business anonymous mode application with comprehensive query capabilities for retrieving context-specific responses. Features querying Amazon Q Business applications created in anonymous mode, support for local machine usage, and response retrieval based on ingested content. Provides QBusinessQueryTool for querying Amazon Q Business applications to get context-specific responses with minimal required permissions. Cannot create, modify, or delete resources, maintaining security boundaries. Ideal for anonymous Q Business querying, knowledge retrieval from Q Business, context-aware responses, and AI-assisted business intelligence. Requires AWS account, Amazon Q Business application in anonymous mode, Python 3.10, uv package manager, and AWS IAM permissions with qbusiness:ChatSync.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.amazon-qbusiness-anonymous-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "QBUSINESS_APPLICATION_ID": "{{env:qbusiness_app_id}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["AI"],
      "capabilities": ["qbusiness_querying", "anonymous_mode", "context_retrieval", "business_intelligence", "knowledge_access"],
      "domains": ["aws", "qbusiness", "business-intelligence", "anonymous", "knowledge"],
      "keywords": ["aws", "mcp", "qbusiness", "anonymous", "business-intelligence", "query", "context"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Create Amazon Q Business application in anonymous mode\\n4. Configure AWS credentials: aws configure\\n5. Configure user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set qbusiness_app_id 'your-qbusiness-application-id'\\n   - vault set log_level 'ERROR' (default: ERROR)\\n6. Ensure IAM permissions for Q Business (least privilege):\\n   - qbusiness:ChatSync\\n7. Test Q Business access: aws qbusiness list-applications"
    },
    {
      "id": 43,
      "server_id": "awslabs.amazon-rekognition-mcp-server",
      "name": "Amazon Rekognition MCP Server",
      "description": "A Model Context Protocol (MCP) server for Amazon Rekognition that enables AI assistants to analyze images using Amazon Rekognition's powerful computer vision capabilities with comprehensive image analysis tools. Features face collection management, face recognition, object and scene detection, content moderation, celebrity recognition, face comparison, and text detection. Provides comprehensive tools including list_collections, index_faces, search_faces_by_image, detect_labels, detect_moderation_labels, recognize_celebrities, compare_faces, and detect_text. Ideal for computer vision workflows, image analysis automation, content moderation, and AI-assisted visual recognition. Requires Python 3.10, uv package manager, AWS credentials with Amazon Rekognition access, and appropriate IAM permissions for Rekognition services.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.amazon-rekognition-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["AI"],
      "capabilities": ["image_analysis", "face_recognition", "object_detection", "content_moderation", "celebrity_recognition", "text_detection"],
      "domains": ["aws", "rekognition", "computer-vision", "image-analysis", "ai"],
      "keywords": ["aws", "mcp", "rekognition", "computer-vision", "face-recognition", "image-analysis", "ai"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Configure user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n5. Ensure IAM permissions for Rekognition:\\n   - rekognition:DetectLabels\\n   - rekognition:DetectFaces\\n   - rekognition:RecognizeCelebrities\\n   - rekognition:DetectText\\n   - rekognition:CompareFaces\\n   - rekognition:SearchFacesByImage\\n   - rekognition:IndexFaces\\n   - rekognition:ListCollections\\n   - rekognition:DetectModerationLabels\\n6. Test Rekognition access: aws rekognition list-collections"
    },
    {
      "id": 44,
      "server_id": "awslabs.amazon-sns-sqs-mcp-server",
      "name": "Amazon SNS/SQS MCP Server",
      "description": "A Model Context Protocol (MCP) server for Amazon SNS/SQS that enables generative AI models to manage SNS Topics and SQS Queues with comprehensive messaging infrastructure capabilities. Features creation, listing, and management of Amazon SNS topics, SNS subscription management, SQS queue creation and management, and message sending and receiving using SNS and SQS. Implements security mechanism that only allows modification of resources created by the MCP server itself through resource tagging for enhanced security. Ideal for messaging infrastructure automation, queue management, notification system setup, and AI-assisted messaging workflows. Requires Python 3.10, uv package manager, and AWS account with permissions to create and manage Amazon SNS/SQS resources.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.amazon-sns-sqs-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["sns_management", "sqs_management", "message_queuing", "notification_management", "resource_tagging"],
      "domains": ["aws", "sns", "sqs", "messaging", "notifications"],
      "keywords": ["aws", "mcp", "sns", "sqs", "messaging", "notifications", "queues"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Configure user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n5. Ensure IAM permissions for SNS/SQS:\\n   - sns:CreateTopic\\n   - sns:DeleteTopic\\n   - sns:ListTopics\\n   - sns:Subscribe\\n   - sns:Unsubscribe\\n   - sns:Publish\\n   - sqs:CreateQueue\\n   - sqs:DeleteQueue\\n   - sqs:ListQueues\\n   - sqs:SendMessage\\n   - sqs:ReceiveMessage\\n6. Test SNS/SQS access: aws sns list-topics && aws sqs list-queues"
    },
    {
      "id": 45,
      "server_id": "awslabs.aws-diagram-mcp-server",
      "name": "AWS Diagram MCP Server",
      "description": "A Model Context Protocol (MCP) server for AWS Diagrams that generates professional diagrams using Python code with comprehensive diagram creation capabilities. Features professional diagram generation, support for multiple diagram types (AWS architecture, sequence, flow, class diagrams), diagram appearance and layout customization, and code scanning for security. Allows creating diagrams using a Python-based Domain Specific Language (DSL) with intelligent diagram generation and layout optimization. Ideal for architecture documentation, system design visualization, infrastructure diagrams, and AI-assisted diagram creation. Requires Python 3.10, uv package manager, GraphViz installation, and development dependencies for comprehensive diagram generation capabilities.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "PUBLIC",
      "command": "uvx",
      "args": ["awslabs.aws-diagram-mcp-server@latest"],
      "env": {
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["diagram_generation", "architecture_visualization", "aws_diagrams", "sequence_diagrams", "flow_diagrams"],
      "domains": ["aws", "diagrams", "visualization", "architecture", "documentation"],
      "keywords": ["aws", "mcp", "diagrams", "visualization", "architecture", "graphviz", "documentation"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Install GraphViz:\\n   - Ubuntu/Debian: sudo apt-get install graphviz\\n   - macOS: brew install graphviz\\n   - Windows: Download from graphviz.org\\n4. Install development dependencies: uv pip install -e '.[dev]'\\n5. Optional user preferences:\\n   - vault set log_level 'ERROR' (default: ERROR)\\n6. Test GraphViz installation: dot -V\\n7. No AWS credentials required for basic functionality"
    },
    {
      "id": 46,
      "server_id": "awslabs.aws-healthomics-mcp-server",
      "name": "AWS HealthOmics MCP Server",
      "description": "A Model Context Protocol (MCP) server that provides AI assistants with comprehensive access to AWS HealthOmics services for genomic workflow management, execution, and analysis. Features workflow management including creation and validation of workflows, version management, and packaging of workflow definitions. Provides workflow execution capabilities with start and monitoring of workflow runs, individual task status tracking, and compute resource configuration. Includes analysis and troubleshooting tools for performance analysis, failure diagnosis, and detailed log retrieval. Ideal for genomic research workflows, bioinformatics pipeline management, healthcare data analysis, and AI-assisted genomic processing. Requires AWS credentials, appropriate IAM permissions for HealthOmics operations, and Python 3.10 with uv package manager.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.aws-healthomics-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DATA"],
      "capabilities": ["healthomics_workflows", "genomic_analysis", "workflow_execution", "bioinformatics_pipelines", "healthcare_data"],
      "domains": ["aws", "healthomics", "genomics", "bioinformatics", "healthcare"],
      "keywords": ["aws", "mcp", "healthomics", "genomics", "bioinformatics", "workflows", "healthcare"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Configure user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n5. Ensure IAM permissions for HealthOmics:\\n   - omics:CreateWorkflow\\n   - omics:GetWorkflow\\n   - omics:ListWorkflows\\n   - omics:StartRun\\n   - omics:GetRun\\n   - omics:ListRuns\\n   - omics:CancelRun\\n6. Test HealthOmics access: aws omics list-workflows"
    },
    {
      "id": 47,
      "server_id": "awslabs.aws-location-mcp-server",
      "name": "Amazon Location Service MCP Server",
      "description": "A Model Context Protocol (MCP) server for Amazon Location Service that provides comprehensive tools to access geographical and location-based capabilities. Features place search using geocoding, place details retrieval by PlaceId, reverse geocoding coordinates to addresses, nearby place searching, finding places currently open, route calculation between locations, and route waypoint optimization. Supports multiple travel modes for route calculation, flexible search radius and result expansion, and temporary credential management. Ideal for location-based applications, mapping and navigation, geospatial analysis, and AI-assisted location services. Requires AWS account with Amazon Location Service enabled, Python 3.10+, uv package manager, and configured AWS credentials.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.aws-location-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "LOCATION_PLACE_INDEX": "{{env:location_place_index}}",
        "LOCATION_ROUTE_CALCULATOR": "{{env:location_route_calculator}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["geocoding", "reverse_geocoding", "place_search", "route_calculation", "location_services", "mapping"],
      "domains": ["aws", "location", "mapping", "geocoding", "navigation"],
      "keywords": ["aws", "mcp", "location", "geocoding", "mapping", "navigation", "places"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Set up Amazon Location Service resources\\n5. Configure user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set location_place_index 'your-place-index-name'\\n   - vault set location_route_calculator 'your-route-calculator-name'\\n   - vault set log_level 'ERROR' (default: ERROR)\\n6. Ensure IAM permissions for Location Service:\\n   - geo:SearchPlaceIndexForPosition\\n   - geo:SearchPlaceIndexForText\\n   - geo:GetPlace\\n   - geo:CalculateRoute\\n7. Test Location access: aws location list-place-indexes"
    },
    {
      "id": 48,
      "server_id": "awslabs.aws-serverless-mcp-server",
      "name": "AWS Serverless MCP Server",
      "description": "An open-source tool that combines AI assistance with serverless expertise to streamline how developers build serverless applications with comprehensive serverless development guidance. Features AI-powered serverless development guidance, comprehensive tooling for serverless application lifecycle, web application deployment and management, observability and metrics retrieval, infrastructure as code (IaC) guidance, and event schema discovery. Provides contextual AI assistance to help developers make informed decisions about serverless architecture, implementation, and deployment. Ideal for serverless application development, AWS SAM projects, Lambda function management, and AI-assisted serverless workflows. Requires AWS account with configured credentials, Python 3.10+, uv package manager, AWS SAM CLI, and AWS CLI installation.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.aws-serverless-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["serverless_guidance", "sam_integration", "lambda_management", "iac_guidance", "observability", "event_schemas"],
      "domains": ["aws", "serverless", "lambda", "sam", "iac"],
      "keywords": ["aws", "mcp", "serverless", "lambda", "sam", "iac", "deployment"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Install AWS SAM CLI: https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/install-sam-cli.html\\n4. Install AWS CLI: https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html\\n5. Configure AWS credentials: aws configure\\n6. Configure user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n7. Ensure IAM permissions for serverless operations:\\n   - lambda:*\\n   - cloudformation:*\\n   - iam:*\\n   - apigateway:*\\n   - s3:*\\n8. Test SAM CLI: sam --version"
    },
    {
      "id": 49,
      "server_id": "awslabs.aws-support-mcp-server",
      "name": "AWS Support MCP Server",
      "description": "A Model Context Protocol (MCP) server implementation for interacting with the AWS Support API with comprehensive support case management capabilities. Features creation and management of AWS support cases, case information and communications retrieval, adding communications to existing cases, support case resolution, and determination of appropriate issue type, service code, category code, and severity level. Requires Business, Enterprise On-Ramp, or Enterprise Support plan for API access. Ideal for support case automation, customer service workflows, issue tracking and management, and AI-assisted support operations. Requires Python 3.7+, AWS credentials with Support API access, and appropriate AWS support plan subscription.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.aws-support-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["support_case_management", "case_communications", "issue_tracking", "support_api", "case_resolution"],
      "domains": ["aws", "support", "customer-service", "case-management"],
      "keywords": ["aws", "mcp", "support", "cases", "customer-service", "api", "tickets"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Ensure you have Business, Enterprise On-Ramp, or Enterprise Support plan\\n4. Configure AWS credentials: aws configure\\n5. Configure user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n6. Ensure IAM permissions for Support API:\\n   - support:CreateCase\\n   - support:DescribeCases\\n   - support:DescribeCommunications\\n   - support:AddCommunicationToCase\\n   - support:ResolveCase\\n   - support:DescribeServices\\n   - support:DescribeSeverityLevels\\n7. Test Support API access: aws support describe-services"
    },
    {
      "id": 50,
      "server_id": "awslabs.amazon-qindex-mcp-server",
      "name": "AWS Labs Amazon Q Index MCP Server",
      "description": "A Model Context Protocol (MCP) server designed to facilitate integration with Amazon Q Business's SearchRelevantContent API for Independent Software Vendors (ISVs) who are AWS registered data accessors. Features Boto3 client implementation for Q Business interactions, support for multiple authentication methods, token-based authorization, cross-account search capabilities, and error handling for Q Business API responses. Enables ISVs to integrate with enterprise customer Q Business applications through secure cross-account access. Requires two AWS accounts: one as ISV running the application and one as enterprise customer running Amazon Q Business. Ideal for ISV integrations, enterprise Q Business access, cross-account search workflows, and partner ecosystem integrations. Requires registered data accessor status, IAM Identity Center instance, Amazon Q Business application configured with IAM IDC, Python 3.10, and uv package manager.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "pip",
      "args": ["install", "-e", "."],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "QBUSINESS_APPLICATION_ID": "{{env:qbusiness_app_id}}",
        "QINDEX_TOKEN": "{{env:qindex_token}}"
      },
      "categories": ["AI"],
      "capabilities": ["qbusiness_integration", "cross_account_search", "isv_integration", "token_authorization", "enterprise_search"],
      "domains": ["aws", "qbusiness", "isv", "enterprise", "search"],
      "keywords": ["aws", "mcp", "qindex", "qbusiness", "isv", "enterprise", "search"],
      "setup_instructions": "1. Ensure you are a registered AWS data accessor (ISV)\\n2. Set up two AWS accounts: ISV account and enterprise customer account\\n3. Configure IAM Identity Center instance\\n4. Set up Amazon Q Business application with IAM IDC\\n5. Install Python 3.10 and uv\\n6. Clone repository and install:\\n   git clone [repository-url]\\n   cd mcp/src/amazon-qindex-mcp-server/\\n   pip install -e .\\n7. Configure connection details:\\n   - vault set aws_profile 'your-isv-profile'\\n   - vault set aws_region 'your-region'\\n   - vault set qbusiness_app_id 'customer-qbusiness-app-id'\\n   - vault set qindex_token 'your-access-token'\\n8. Ensure cross-account permissions are properly configured"
    },
    {
      "id": 51,
      "server_id": "awslabs.aws-documentation-mcp-server",
      "name": "AWS Documentation MCP Server",
      "description": "A Model Context Protocol (MCP) server for AWS Documentation that provides comprehensive access to AWS documentation with content retrieval and search capabilities. Features reading AWS documentation pages and converting to markdown, searching AWS documentation using official search API (global only), getting content recommendations for documentation pages (global only), and retrieving available AWS services list for China regions. Supports both global and China AWS documentation partitions with configurable deployment options. Ideal for documentation access workflows, AWS reference integration, developer documentation tools, and AI-assisted AWS learning. Requires Python 3.10+, uv package manager, and MCP client configuration. No AWS credentials required for basic documentation access.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "PUBLIC",
      "command": "uvx",
      "args": ["awslabs.aws-documentation-mcp-server@latest"],
      "env": {
        "AWS_DOCS_PARTITION": "{{env:aws_docs_partition}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DOCUMENTATION"],
      "capabilities": ["documentation_access", "markdown_conversion", "documentation_search", "content_recommendations", "china_region_support"],
      "domains": ["aws", "documentation", "reference", "learning"],
      "keywords": ["aws", "mcp", "documentation", "reference", "markdown", "search"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Optional user preferences:\\n   - vault set aws_docs_partition 'global' or 'china' (default: global)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n4. No AWS credentials required for basic functionality\\n5. Configure MCP server in your MCP client\\n6. Alternative: Use Docker for deployment\\n7. Test access to AWS documentation search"
    },
    {
      "id": 52,
      "server_id": "awslabs.aws-msk-mcp-server",
      "name": "AWS Labs Amazon MSK MCP Server",
      "description": "An AWS Labs Model Context Protocol (MCP) server for Amazon Managed Streaming for Kafka (MSK) with comprehensive cluster and configuration management capabilities. Features cluster management (create, describe, update MSK clusters), configuration management for MSK configurations, VPC connection management, monitoring and telemetry, security management, and best practices recommendations. Supports read/write mode options with configurable --allow-writes flag for enhanced security control. Ideal for MSK cluster creation and configuration, monitoring cluster performance, implementing best practices, managing security controls, and troubleshooting cluster issues. Requires Python 3.10, uv package manager, and AWS credentials with appropriate MSK permissions.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.aws-msk-mcp-server@latest", "{{env:msk_allow_writes_flag}}"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DATA"],
      "capabilities": ["msk_cluster_management", "kafka_configuration", "vpc_connections", "monitoring_telemetry", "security_management", "best_practices"],
      "domains": ["aws", "msk", "kafka", "streaming", "messaging"],
      "keywords": ["aws", "mcp", "msk", "kafka", "streaming", "messaging", "clusters"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Configure user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set msk_allow_writes_flag '--allow-writes' (enables write operations)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n5. Ensure IAM permissions for MSK:\\n   - kafka:CreateCluster\\n   - kafka:DescribeCluster\\n   - kafka:UpdateClusterConfiguration\\n   - kafka:ListClusters\\n   - kafka:CreateConfiguration\\n   - kafka:DescribeConfiguration\\n   - kafka:ListConfigurations\\n   - ec2:DescribeVpcs\\n   - ec2:DescribeSubnets\\n6. Test MSK access: aws kafka list-clusters"
    },
    {
      "id": 53,
      "server_id": "awslabs.aws-pricing-mcp-server",
      "name": "AWS Pricing MCP Server",
      "description": "An MCP server for accessing real-time AWS pricing information and providing comprehensive cost analysis capabilities. Features AWS pricing discovery with service catalog exploration, pricing attribute discovery, real-time pricing queries, multi-region pricing comparisons, and bulk pricing data access. Provides cost analysis and planning with detailed cost report generation, infrastructure project analysis, architecture pattern guidance, and cost optimization recommendations. Supports natural language pricing queries to ask pricing questions in plain English and retrieve comprehensive pricing information with instant answers from AWS Pricing API. Ideal for cost planning and analysis, pricing research workflows, architecture cost estimation, and AI-assisted cost optimization. Requires Python 3.10, uv package manager, and AWS credentials with pricing permissions. Pricing API calls are free of charge.",
      "version": "1.0.0",
      "execution_type": "LOCAL",
      "security_level": "CREDENTIALS",
      "command": "uvx",
      "args": ["awslabs.aws-pricing-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "{{env:aws_profile}}",
        "AWS_REGION": "{{env:aws_region}}",
        "FASTMCP_LOG_LEVEL": "{{env:log_level}}"
      },
      "categories": ["DEVELOPMENT"],
      "capabilities": ["pricing_discovery", "cost_analysis", "pricing_queries", "cost_optimization", "multi_region_pricing", "natural_language_queries"],
      "domains": ["aws", "pricing", "cost", "analysis", "optimization"],
      "keywords": ["aws", "mcp", "pricing", "cost", "analysis", "optimization", "estimates"],
      "setup_instructions": "1. Ensure uv is installed: curl -LsSf https://astral.sh/uv/install.sh | sh\\n2. Install Python 3.10: uv python install 3.10\\n3. Configure AWS credentials: aws configure\\n4. Configure user preferences:\\n   - vault set aws_profile 'your-aws-profile' (default: default)\\n   - vault set aws_region 'your-region' (default: us-east-1)\\n   - vault set log_level 'ERROR' (default: ERROR)\\n5. Ensure IAM permissions for Pricing API:\\n   - pricing:GetProducts\\n   - pricing:GetAttributeValues\\n   - pricing:DescribeServices\\n6. Test Pricing API access: aws pricing describe-services\\n7. Note: Pricing API calls are free of charge\\n8. Supports Linux, macOS, and Windows"
    }
  ]
}